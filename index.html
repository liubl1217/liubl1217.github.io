<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Benlin Liu</title>
  
  <meta name="author" content="Benlin Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon_uw.png">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Benlin Liu</name>
              </p>
              <p> 
                I am a Ph.D. student in <a href="https://www.cs.washington.edu"> Paul G. Allen School of Computer Science & Engineering</a>, <a href="https://www.washington.edu"> University of Washington</a>, working with <a href="https://www.smseitz.com"> Steven M. Seitz</a>, <a href="https://homes.cs.washington.edu/~curless/"> Brian Curless</a>, and <a href="https://homes.cs.washington.edu/~kemelmi/"> Ira Kemelmacher-Shlizerman</a>. I am affiliated with <a href="https://grail.cs.washington.edu"> UW Graphics and Imaging Laboratory (GRAIL)</a> and <a href="https://realitylab.uw.edu"> UW Reality Lab</a>.
              </p>
              <p>
               I receive my master degree from <a href="https://www.cs.ucla.edu"> Department of Computer Science</a>, <a href="https://www.ucla.edu"> UCLA</a>, where I was a research assistant under the supervision of Prof. <a href="http://web.cs.ucla.edu/~chohsieh/"> Cho-jui Hsieh </a>. I also collaborated with Prof. <a href="https://xiaolonw.github.io"> Xiaolong Wang </a> at <a href="https://ucsd.edu"> UCSD </a>. I obtained my BEng. degree from the <a href="https://www.ee.tsinghua.edu.cn/en/"> Department of Electronic Engineering </a>, <a href="https://www.tsinghua.edu.cn/en/"> Tsinghua University </a>, and I worked with Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a> of the <a href="https://www.au.tsinghua.edu.cn"> Department of Automation </a>. During undergraduate, I visited the <a href="https://www.grasp.upenn.edu"> GRASP Lab</a> at <a href="https://www.upenn.edu"> University of Pennsylvania</a> and worked with Prof. <a href="https://www.cis.upenn.edu/~jshi/"> Jianbo Shi</a>.
              </p>
              <p>
              My current research interest is at the intersection of compution vision and computer graphics, with an emphasis on neural rendering. 
              Past research is more about efficient machine learning model and how to learn more generlizable vision model in a data-efficient way.
              </p>
              <p>
              My ongoing research project is being funded by UW Reality Lab-Meta Fellowship.
              </p>

              <p style="text-align:center">
                <a href="mailto:liubl@cs.washington.edu">Email</a> &nbsp/&nbsp
                <a href="files/CV_Benlin.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=fNl-ZkIAAAAJ&hl=zh-CN&oi=ao"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/liubl1217"> Github </a> &nbsp/&nbsp
                <a href="https://twitter.com/LiuBenlin"> Twitter </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/selfie.jpeg">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                <b>2022-06:</b> I am greatly honored to be chosen as UW Reality Lab-Meta Fellow!
              </li>
              <li style="margin: 5px;" >
                <b>2021-09:</b> <a href="https://dynamicvit.ivg-research.xyz"> DynamicViT</a> is accepted to <a href="https://neurips.cc/Conferences/2021">NeurIPS 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2021-07:</b> Two papers are accepted to <a href="https://iccv2021.thecvf.com">ICCV 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2020-12:</b> One paper on image classification is accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2020-07:</b> One paper on knowledge distillation is accepted by <a href="https://eccv2020.eu/">ECCV 2020</a>.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                * indicates equal contribution
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/dynamicViT.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification </papertitle>
              <br>
              Yongming Rao, Wenliang Zhao, <strong>Benlin Liu</strong>, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>Thirty-fifth Conference on Neural Information Processing Systems  (<strong>NeurIPS</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2106.02034.pdf">[Paper]</a><a href="https://dynamicvit.ivg-research.xyz">[Project Page]</a><a href="https://github.com/raoyongming/DynamicViT">[Code]</a><a href="https://www.youtube.com/watch?v=3gfizSuIf0s">[Video]</a>
              <br>
              <p></p>
              <p>We propose a dynamic token sparsification framework to prune redundant tokens progressively and dynamically for vision transformer acceleration.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/RandomRooms.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>RandomRooms: Unsupervised Pre-training from Synthetic Shapes and Randomized Layouts for 3D Object Detection </papertitle>
              <br>
              Yongming Rao*, <strong>Benlin Liu*</strong>, Yi Wei, Jiwen Lu, Cho-Jui Hsieh, Jie Zhou
              <br>
              <em>IEEE/CVF International Conference on Computer Vision  (<strong>ICCV</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2108.07794.pdf">[Paper]</a>
              <br>
              <p></p>
              <p>We propose to generate random layouts of a scene by making use of the objects in the synthetic CAD dataset and learn the 3D scene representation by applying object-level contrastive learning on two random scenes generated from the same set of synthetic objects.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/cyc-conf.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Robust Object Detection via Instance-Level Temporal Cycle Confusion </papertitle>
              <br>
              Xin Wang,  <strong>Benlin Liu*</strong>, Thomas E. Huang*, Fisher Yu, Xiaolong Wang, Joseph E. Gonzalez, Trevor Darrell
              <br>
              <em>IEEE/CVF International Conference on Computer Vision  (<strong>ICCV</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2104.08381">[Paper]</a><a href="https://xinw.ai/cyc-conf">[Project Page]</a>
              <br>
              <p></p>
              <p>We introduce a new self-supervised task on videos to improve the out-of-domain generalization of object detectors.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/WassClf.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Multi-ProxyWasserstein Classifier for Image Classification</papertitle>
              <br>
              <strong>Benlin Liu*</strong>, Yongming Rao*, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>35th AAAI Conference on Artificial Intelligence  (<strong>AAAI</strong>)</em>, 2021
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17045/16852">[Paper]</a>
              <br>
              <p></p>
              <p>We present a new Multi-Proxy Wasserstein Classifier to imporve the image classification models by calculating a non-uniform matching
                flow between the elements in the feature map of a sample and multiple proxies of a class using optimal transport theory.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/metadistiller.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down Distillation</papertitle>
              <br>
              <strong>Benlin Liu</strong>, Yongming Rao, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>16th European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.12094">[Paper]</a>
              <br>
              <p></p>
              <p>We boost the performance of CNNs by learning soft targets for shallow layers via meta-learning.</p>
            </td>
          </tr>
          
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> ECCV 2022, ICLR 2022, CVPR 2021-2022, WACV 2021-2022
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=xC8PdNDKmVJ8msT1wUO5JX3M73M48KosFGCdR656Uao"></script>
	  </div>        
	  <br>
	    &copy; Benlin Liu | Last updated: Jun 9, 2022
</center></p>
</body>

</html>

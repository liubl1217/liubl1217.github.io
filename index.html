<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Benlin Liu</title>
  
  <meta name="author" content="Benlin Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon_uw.png">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Benlin Liu</name>
              </p>
              <p> 
                I am a Ph.D. student in <a href="https://www.cs.washington.edu"> Paul G. Allen School of Computer Science & Engineering</a>, <a href="https://www.washington.edu"> University of Washington</a>, working with <a href="https://www.smseitz.com"> Steven M. Seitz</a>, <a href="https://homes.cs.washington.edu/~curless/"> Brian Curless</a>, and <a href="https://homes.cs.washington.edu/~kemelmi/"> Ira Kemelmacher-Shlizerman</a>. I am affiliated with <a href="https://grail.cs.washington.edu"> UW Graphics and Imaging Laboratory (GRAIL)</a>.
              </p>
              <p>
               I receive my master degree from <a href="https://www.cs.ucla.edu"> Department of Computer Science</a>, <a href="https://www.ucla.edu"> UCLA</a>, where I was a research assistant under the supervision of Prof. <a href="http://web.cs.ucla.edu/~chohsieh/"> Cho-jui Hsieh </a>. I also collaborated with Prof. <a href="https://xiaolonw.github.io"> Xiaolong Wang </a> at <a href="https://ucsd.edu"> UCSD </a>. I obtained my BEng. degree from the <a href="https://www.ee.tsinghua.edu.cn/en/"> Department of Electronic Engineering </a>, <a href="https://www.tsinghua.edu.cn/en/"> Tsinghua University </a>, and I worked with Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a> of the <a href="https://www.au.tsinghua.edu.cn"> Department of Automation </a>. During undergraduate, I visited the <a href="https://www.grasp.upenn.edu"> GRASP Lab</a> at <a href="https://www.upenn.edu"> University of Pennsylvania</a> and worked with Prof. <a href="https://www.cis.upenn.edu/~jshi/"> Jianbo Shi</a>.
              </p>
              <p>
              My current research interest is at the intersection of compution vision and machine learning, with a current focus on generative model and self-supervised learning. 
              Past research is more about efficient machine learning model and how to learn more generlizable vision model in a data-efficient way.
              </p>


              <p style="text-align:center">
                <a href="mailto:liubl@cs.washington.edu">Email</a> &nbsp/&nbsp
                <a href="files/CV_Benlin.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=fNl-ZkIAAAAJ&hl=zh-CN&oi=ao"> Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/liubl1217"> Github </a> &nbsp/&nbsp
                <a href="https://twitter.com/LiuBenlin"> Twitter </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/selfie.jpeg">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                <b>2022-06:</b> I am greatly honored to be chosen as UW Reality Lab-Meta Fellow!
              </li>
              <li style="margin: 5px;" >
                <b>2021-09:</b> <a href="https://dynamicvit.ivg-research.xyz"> DynamicViT</a> is accepted to <a href="https://neurips.cc/Conferences/2021">NeurIPS 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2021-07:</b> Two papers are accepted to <a href="https://iccv2021.thecvf.com">ICCV 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2020-12:</b> One paper on image classification is accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.
              </li>
              <li style="margin: 5px;" >
                <b>2020-07:</b> One paper on knowledge distillation is accepted by <a href="https://eccv2020.eu/">ECCV 2020</a>.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                * indicates equal contribution
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/tifa.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering </papertitle>
              <br>
              Yushi Hu, <strong>Benlin Liu</strong>, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, Noah A. Smith
              <br>
              <em>In Submission</em>
              <br>
              <a href="https://arxiv.org/abs/2303.11897">[Paper]</a><a href="https://tifa-benchmark.github.io">[Project Page]</a><a href="https://github.com/Yushi-Hu/tifa">[Code]</a>
              <br>
              <p></p>
              <p>Fine-grained and accurate evaluation of synthesized images using Image-to-Text Models (e.g. GPT-4, BLIP-2, etc.) and Large Language Models (e.g. GPT-3.5). More accurate than CLIP!</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/vpd.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Unleashing Text-to-Image Diffusion Models for Visual Perception </papertitle>
              <br>
              Wenliang Zhao*, Yongming Rao*, Zuyan Liu*, <strong>Benlin Liu</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>In Submission</em>
              <br>
              <a href="https://arxiv.org/abs/2303.02153">[Paper]</a><a href="https://vpd.ivg-research.xyz">[Project Page]</a><a href="https://github.com/wl-zhao/VPD">[Code]</a>
              <br>
              <p></p>
              <p>Text-to-Image generation models (e.g. Stable Diffusion) are not only for creating cool stuff, but can also be applied to multiple dense prediction tasks!</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/dynamicViT.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification </papertitle>
              <br>
              Yongming Rao, Wenliang Zhao, <strong>Benlin Liu</strong>, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>Thirty-fifth Conference on Neural Information Processing Systems  (<strong>NeurIPS</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2106.02034.pdf">[Paper]</a><a href="https://dynamicvit.ivg-research.xyz">[Project Page]</a><a href="https://github.com/raoyongming/DynamicViT">[Code]</a><a href="https://www.youtube.com/watch?v=3gfizSuIf0s">[Video]</a>
              <br>
              <p></p>
              <p>We propose a dynamic token sparsification framework to prune redundant tokens progressively and dynamically for vision transformer acceleration.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/RandomRooms.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>RandomRooms: Unsupervised Pre-training from Synthetic Shapes and Randomized Layouts for 3D Object Detection </papertitle>
              <br>
              Yongming Rao*, <strong>Benlin Liu*</strong>, Yi Wei, Jiwen Lu, Cho-Jui Hsieh, Jie Zhou
              <br>
              <em>IEEE/CVF International Conference on Computer Vision  (<strong>ICCV</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2108.07794.pdf">[Paper]</a>
              <br>
              <p></p>
              <p>We propose to generate random layouts of a scene by making use of the objects in the synthetic CAD dataset and learn the 3D scene representation by applying object-level contrastive learning on two random scenes generated from the same set of synthetic objects.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/cyc-conf.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Robust Object Detection via Instance-Level Temporal Cycle Confusion </papertitle>
              <br>
              Xin Wang,  <strong>Benlin Liu*</strong>, Thomas E. Huang*, Fisher Yu, Xiaolong Wang, Joseph E. Gonzalez, Trevor Darrell
              <br>
              <em>IEEE/CVF International Conference on Computer Vision  (<strong>ICCV</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2104.08381">[Paper]</a><a href="https://xinw.ai/cyc-conf">[Project Page]</a>
              <br>
              <p></p>
              <p>We introduce a new self-supervised task on videos to improve the out-of-domain generalization of object detectors.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/WassClf.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Multi-ProxyWasserstein Classifier for Image Classification</papertitle>
              <br>
              <strong>Benlin Liu*</strong>, Yongming Rao*, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>35th AAAI Conference on Artificial Intelligence  (<strong>AAAI</strong>)</em>, 2021
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17045/16852">[Paper]</a>
              <br>
              <p></p>
              <p>We present a new Multi-Proxy Wasserstein Classifier to imporve the image classification models by calculating a non-uniform matching
                flow between the elements in the feature map of a sample and multiple proxies of a class using optimal transport theory.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/metadistiller.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down Distillation</papertitle>
              <br>
              <strong>Benlin Liu</strong>, Yongming Rao, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh
              <br>
              <em>16th European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2008.12094">[Paper]</a>
              <br>
              <p></p>
              <p>We boost the performance of CNNs by learning soft targets for shallow layers via meta-learning.</p>
            </td>
          </tr>
          
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b>  CVPR 2021-2023, WACV 2021-2023, NeurIPS 2023, ICCV 2023, ECCV 2022, ICLR 2022
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
 
<p><center>
	  <div id="clustrmaps-widget" style="width:5%">
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=xC8PdNDKmVJ8msT1wUO5JX3M73M48KosFGCdR656Uao"></script>
	  </div>        
	  <br>
	    &copy; Benlin Liu | Last updated: Apr 3, 2023
</center></p>
</body>

</html>
